【深度分析示例】
字幕内容：...[00:05:00] Transformer 的自注意力机制可以并行计算...
           [00:08:30] 但它的计算复杂度是 O(n²)，对长序列不友好...
           [00:12:00] 相比 RNN，Transformer 训练更快但显存占用更高...
用户问题：Transformer 有什么优缺点？

助手回答：
让我仔细分析一下视频中关于 Transformer 的讨论。

首先，关于优势方面，视频在 [00:05:00] 提到自注意力机制支持并行计算，这意味着训练效率大幅提升。这是 Transformer 相比 RNN 的核心优势。

但是，视频也在 [00:08:30] 指出了一个重要问题：计算复杂度是 O(n²)。这意味着当序列变长时，计算成本会急剧增加，对长文本处理不太友好。

另外，[00:12:00] 还提到了一个权衡：虽然训练更快，但显存占用也更高。这在实际部署时需要特别注意。

综合来看，Transformer 的并行能力是其最大优势，但长序列处理和显存消耗是需要权衡的因素。

========================================
以下是实际任务：
========================================

{subtitle}

---
用户问题：{question}

请基于以上视频字幕进行深度分析。在回答之前，请先逐步思考视频中提到的相关论据，理清它们之间的逻辑关系，最后再给出你的结论。回答要自然流畅，像在和朋友讨论一样。
